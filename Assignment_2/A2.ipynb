{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.1\n",
    "\n",
    "### One Vs All: \n",
    "#### One Vs All is also known as One vs Rest is a heuristic method for Binary classification algorithms in order to perform Multi-Class classification. It splitts the Multi-Class Dataset into multiple binary classification problem. After splitting the dataset into multiple binary classes it trains the binary classifier on each of the classes and then the prediction is made for the multiclass. \n",
    "\n",
    "### One vs One \n",
    "#### One vs One is another heuristic technique that is used for Multiclass Class classification using binary Classification. Similar to One Vs All it splits the dataset into one binary data for each class vs every other class.  \n",
    "\n",
    "#### For the Training of the 'one vs one' and 'one vs all' strategy the dataset is divided into Training set and Testing set in the ratio of 70:30. Then the train and test dataset is Standardised and passed to the Linear SVM for Training. The Test is used for prediction in order to check the Generality of the Classifier on the unseen dataset. This is the main procedure for the Training of SVM.\n",
    "\n",
    "#### From [sklearn](https://scikit-learn.org/stable/modules/svm.html) the Training and Classification procedure is as follows: \n",
    "\n",
    "SVC in Sklearn implements the “one-versus-one” method for multi-class classification and this is done by finding the total number of Classifiers using the equation n_classes * (n_classes - 1) / 2 and then the classifiers are constructed and each one trains data from the two classes. In order to be consistent with the interface of other classifiers, in addition, the decision_function_shape option allows us to monotonically transform the results of the “one-versus-one” classifiers to a “one-vs-rest” decision function of shape (n_samples, n_classes).\n",
    "\n",
    "\n",
    "#### In addition, from the [Paper](https://ieeexplore.ieee.org/document/6575194) the algorithm is as follows for the Training and Classification Procedure: \n",
    "\n",
    "1: First of all we Split X into two parts, X1 for training and X2 for validation\n",
    "\n",
    "2: In each of the base learner bi∈T do\n",
    "\n",
    "3: The classification model is: ClassificationModeli←Train(X1,bi,method);\n",
    "\n",
    "4: Oi←Validate(X2,bi,ClassificationModeli,method);\n",
    "\n",
    "5: end for\n",
    "\n",
    "6: OT←⋃Oi;\n",
    "\n",
    "7: Find the correlation matrix A for OT;\n",
    "\n",
    "8: Sort out the highly correlated groups of base learners, C, from A\n",
    "\n",
    "9: Find a CPT for each group c⊂C of highly correlated classifiers using O;\n",
    "\n",
    "10: k←0;\n",
    "\n",
    "11: (C(k),T(k))←(C,T);\n",
    "\n",
    "12: if opt=1 then ▹ Further optimizations desired\n",
    "\n",
    "13: Untill convergence or stopping criteria do\n",
    "\n",
    "14: do Simplification. (Ctmp,Ttmp)← Simplification(C(k),T(k),X,method); ▹ Optimization 1\n",
    "\n",
    "15: do Replacement. (C(k+1),T(k+1))← Replacement(Ctmp,Ttmp,X,method); ▹ Optimization 2\n",
    "\n",
    "16: k←k+1;\n",
    "\n",
    "17: end while\n",
    "\n",
    "18: end if\n",
    "\n",
    "19: (C(final),T(final))←(C(k),T(k));\n",
    "\n",
    "20: Classify xt according to 5 using the set of base learners Tfinal and groups of highly correlated base learners Cfinal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Necessary Packages \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the DatasetB \n",
    "dataB = pd.read_csv('Dataset/DataB.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "DataB: \n      sepallength  sepalwidth  petallength  petalwidth           class\n0            5.1         3.5          1.4         0.2     Iris-setosa\n1            4.9         3.0          1.4         0.2     Iris-setosa\n2            4.7         3.2          1.3         0.2     Iris-setosa\n3            4.6         3.1          1.5         0.2     Iris-setosa\n4            5.0         3.6          1.4         0.2     Iris-setosa\n..           ...         ...          ...         ...             ...\n145          6.7         3.0          5.2         2.3  Iris-virginica\n146          6.3         2.5          5.0         1.9  Iris-virginica\n147          6.5         3.0          5.2         2.0  Iris-virginica\n148          6.2         3.4          5.4         2.3  Iris-virginica\n149          5.9         3.0          5.1         1.8  Iris-virginica\n\n[150 rows x 5 columns]\n"
    }
   ],
   "source": [
    "# DataB Display\n",
    "print(\"DataB: \\n\" ,dataB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "sepallength    0\nsepalwidth     0\npetallength    0\npetalwidth     0\nclass          0\ndtype: int64"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# Check for Null values \n",
    "dataB.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all the features of the DataB \n",
    "dataB_X = dataB.drop(['class'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "     sepallength  sepalwidth  petallength  petalwidth\n0            5.1         3.5          1.4         0.2\n1            4.9         3.0          1.4         0.2\n2            4.7         3.2          1.3         0.2\n3            4.6         3.1          1.5         0.2\n4            5.0         3.6          1.4         0.2\n..           ...         ...          ...         ...\n145          6.7         3.0          5.2         2.3\n146          6.3         2.5          5.0         1.9\n147          6.5         3.0          5.2         2.0\n148          6.2         3.4          5.4         2.3\n149          5.9         3.0          5.1         1.8\n\n[150 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sepallength</th>\n      <th>sepalwidth</th>\n      <th>petallength</th>\n      <th>petalwidth</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5.1</td>\n      <td>3.5</td>\n      <td>1.4</td>\n      <td>0.2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4.9</td>\n      <td>3.0</td>\n      <td>1.4</td>\n      <td>0.2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.7</td>\n      <td>3.2</td>\n      <td>1.3</td>\n      <td>0.2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4.6</td>\n      <td>3.1</td>\n      <td>1.5</td>\n      <td>0.2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5.0</td>\n      <td>3.6</td>\n      <td>1.4</td>\n      <td>0.2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>145</th>\n      <td>6.7</td>\n      <td>3.0</td>\n      <td>5.2</td>\n      <td>2.3</td>\n    </tr>\n    <tr>\n      <th>146</th>\n      <td>6.3</td>\n      <td>2.5</td>\n      <td>5.0</td>\n      <td>1.9</td>\n    </tr>\n    <tr>\n      <th>147</th>\n      <td>6.5</td>\n      <td>3.0</td>\n      <td>5.2</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>148</th>\n      <td>6.2</td>\n      <td>3.4</td>\n      <td>5.4</td>\n      <td>2.3</td>\n    </tr>\n    <tr>\n      <th>149</th>\n      <td>5.9</td>\n      <td>3.0</td>\n      <td>5.1</td>\n      <td>1.8</td>\n    </tr>\n  </tbody>\n</table>\n<p>150 rows × 4 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "dataB_X "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Target for the DataB: \n 0         Iris-setosa\n1         Iris-setosa\n2         Iris-setosa\n3         Iris-setosa\n4         Iris-setosa\n            ...      \n145    Iris-virginica\n146    Iris-virginica\n147    Iris-virginica\n148    Iris-virginica\n149    Iris-virginica\nName: class, Length: 150, dtype: object\n"
    }
   ],
   "source": [
    "# Collect the Target Variables \n",
    "dataB_y = dataB['class']\n",
    "print(\" Target for the DataB: \\n\", dataB_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Unique Values in DataB: \n ['Iris-setosa' 'Iris-versicolor' 'Iris-virginica']\n"
    }
   ],
   "source": [
    "# Check the Unique values in the Target\n",
    "print(\"Unique Values in DataB: \\n\", dataB_y.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the Labels to Numbers \n",
    "le = LabelEncoder()\n",
    "dataB_y_num = le.fit_transform(dataB_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Transformed Values of the Target: \n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]\n"
    }
   ],
   "source": [
    "print(\" Transformed Values of the Target: \\n\",dataB_y_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset in the ratio of 70:30  \n",
    "X_train, X_test, y_train, y_test = train_test_split(dataB_X, dataB_y_num, test_size = 0.30, random_state = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardise the dataset \n",
    "ss = StandardScaler()\n",
    "X_train_std = ss.fit_transform(X_train)\n",
    "X_test_std = ss.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One vs all Classification  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initalize the Class with linear and One vs all method \n",
    "svm_ovr = SVC(kernel= 'linear', decision_function_shape= 'ovr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the dataset on the SVM classifier \n",
    "svm_ovr.fit(X_train_std, y_train)\n",
    "y_pred_ovr = svm_ovr.predict(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Accuracy Score for One vs all Method:  93.33333333333333\n"
    }
   ],
   "source": [
    "# Accuracy Score \n",
    "acc_score = accuracy_score(y_test, y_pred_ovr)\n",
    "print(\"Accuracy Score for One vs all Method: \", acc_score*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Classification Report for the One Vs All Method Using Kernel = 'Linear': \n                  precision    recall  f1-score   support\n\n    Iris-setosa       1.00      1.00      1.00        19\nIris-versicolor       1.00      0.77      0.87        13\n Iris-virginica       0.81      1.00      0.90        13\n\n       accuracy                           0.93        45\n      macro avg       0.94      0.92      0.92        45\n   weighted avg       0.95      0.93      0.93        45\n\n"
    }
   ],
   "source": [
    "# Check the Categorical report for the Classifier \n",
    "print(\"Classification Report for the One Vs All Method Using Kernel = 'Linear': \\n\", classification_report(le.inverse_transform(y_test), le.inverse_transform(y_pred_ovr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Confusion Matrix for One Vs All Method: \n [[19  0  0]\n [ 0 10  3]\n [ 0  0 13]]\n"
    }
   ],
   "source": [
    "# Confusion Matrix for the predicted value \n",
    "print(\"Confusion Matrix for One Vs All Method: \\n\", confusion_matrix(y_test, y_pred_ovr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One vs One Classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initilaze the Classifier with one vs one method and linear kernel \n",
    "svm_ovo = SVC(kernel= 'linear', decision_function_shape= 'ovo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Test the Dataset \n",
    "svm_ovo.fit(X_train_std, y_train)\n",
    "y_pred_ovo = svm_ovo.predict(X_test_std)\n",
    "acc_score_ovo = accuracy_score(y_test, y_pred_ovo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Accuracy_Score for One Vs One:  93.33333333333333\n"
    }
   ],
   "source": [
    "# Check the Accuracy Score for the Dataset \n",
    "print(\"Accuracy_Score for One Vs One: \", acc_score_ovo*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Classification Report for the One Vs All Method Using Kernel = 'Linear': \n                  precision    recall  f1-score   support\n\n    Iris-setosa       1.00      1.00      1.00        19\nIris-versicolor       1.00      0.77      0.87        13\n Iris-virginica       0.81      1.00      0.90        13\n\n       accuracy                           0.93        45\n      macro avg       0.94      0.92      0.92        45\n   weighted avg       0.95      0.93      0.93        45\n\n"
    }
   ],
   "source": [
    "# Check the Classification Report for the Classifier \n",
    "print(\"Classification Report for the One Vs All Method Using Kernel = 'Linear': \\n\", classification_report(le.inverse_transform(y_test), le.inverse_transform(y_pred_ovo)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Confusion Matrix for One Vs All Method: \n [[19  0  0]\n [ 0 10  3]\n [ 0  0 13]]\n"
    }
   ],
   "source": [
    "# Check the Confusion Matrix for the Classifier \n",
    "print(\"Confusion Matrix for One Vs All Method: \\n\", confusion_matrix(y_test, y_pred_ovo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.3: Decision Tree \n",
    "\n",
    "#### In the Decision Tree a series of questions are asked and every time an answer is obtained, a follow-up question is asked until a conclusion is reached about the label of the class. So each leaf node is given a class label and the non-terminal nodes and other internal nodes which contain the test conditions are used to separate records with different characteristics. A Decision Tree is constructed and then starting from the root node the test conditions are applied and appropriate branch is followed based on the new test condition. This guides to either internal node or to a leaf node. If it guides to the internal node then a new test condition is applied. The class label which is given to the leaf node is then given to that particular record. So for the multi-class classification the split in the decision tree depends on the number of definite values for that particular attribute. Example, if the gender of a person can be male, female or others then an attribute like gender will have a three split with three distinct value like male, female and others. One such approach could be Hunt’s algorithm as in case of multiple classes an attribute that is selected partitions the dataset into smaller dataset and for each value of the attribute the child node is created. This algorithm grows the tree in recursive way until the full tree is obtained. Classification and Regression Trees (CART) does not work for multi classes as it only gives binary splits by taking into account all the 2^(k-1)-1 ways of forming binary partition of k attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Accuracy Score for Decision Tree:  95.55555555555556\n"
    }
   ],
   "source": [
    "# Initialize the Classifier\n",
    "dtclf = DecisionTreeClassifier()\n",
    "dtclf.fit(X_train_std, y_train)\n",
    "y_pred_DT = dtclf.predict(X_test_std)\n",
    "DT_accuracy_store = accuracy_score(y_test, y_pred_DT)\n",
    "print(\"Accuracy Score for Decision Tree: \", DT_accuracy_store*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Classification Report for the One Vs All Method Using Kernel = 'Linear': \n                  precision    recall  f1-score   support\n\n    Iris-setosa       1.00      1.00      1.00        19\nIris-versicolor       1.00      0.85      0.92        13\n Iris-virginica       0.87      1.00      0.93        13\n\n       accuracy                           0.96        45\n      macro avg       0.96      0.95      0.95        45\n   weighted avg       0.96      0.96      0.96        45\n\n"
    }
   ],
   "source": [
    "# Check the Classification Report for the Classifier \n",
    "print(\"Classification Report for the One Vs All Method Using Kernel = 'Linear': \\n\", classification_report(le.inverse_transform(y_test), le.inverse_transform(y_pred_DT)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Confusion Matrix for One Vs All Method: \n [[19  0  0]\n [ 0 11  2]\n [ 0  0 13]]\n"
    }
   ],
   "source": [
    "# Check the Confusion Matrix for the Classifier \n",
    "print(\"Confusion Matrix for One Vs All Method: \\n\", confusion_matrix(y_test, y_pred_DT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comment on the Result: \n",
    "\n",
    "### Question 2.2: \n",
    "\n",
    "#### The accuracy score for Linear SVM classifier with 'one vs one' classification is 93.33%. The precision for Iris-setosa is 1.00, recall is 1.00 and f1-score is 1.00, however, for the value for recall and f1-score decreases for Iris-Versicolor to 0.77 and 0.87 respectively keeping the value of precision to 1.00. The value of precision for Iris-virginica is 0.81 which is lower than that of Iris-setosa and Iris-Versicolor. The values obtained from the Confusion Matrix shows that there are 3 samples in Iris-Versicolor which has been classified as Iris-virginica which is incorrect. Apart from that there is no misclassification for the samples. The results are identical for 'one vs all' case as well.\n",
    "\n",
    "#### The results obtained by Decision Tree is different from that of Linear SVM. In Decision Tree, for Iris-setosa, the value of precision is 1.00, recall is 1.00 and f1-score is 1.00 which is identical to that of linear SVM. For Iris-Versicolor the value of precision is 1.00, recall is 0.85 and f1-score is 0.92 here the value of recall and f1-score is higher than that of Linear SVM. However the precision value for Iris-virginica is 0.87 which is higher than that of linear SVM, the recall value is 1.00 which is same as in the case of Linear SVM and the value of f1-score for Iris-virginica increases by 0.03 for Decision tree to 0.93. In addition, from the value of Confusion Matrix it is clear that only 2 samples of Iris-Versicolor was misclassified as Iris-virginica which is lower than that of Linear SVM.\n",
    "\n",
    "#### Overall the accuracy score for Decision Tree is 95.55% which is higher than that of Linear SVM's 93.33%.  \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1594574849455",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}