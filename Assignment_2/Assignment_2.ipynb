{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Packages\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from scipy.io import loadmat \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Dataset DataA.mat\n",
    "mat_dataA = loadmat(r'C:\\Users\\tonkh\\OneDrive\\Desktop\\ECE 657A\\Assignment\\Assignment2\\Assignment2\\Datasets\\DataA.mat')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset A: \n",
      " {'__header__': b'MATLAB 5.0 MAT-file, Platform: PCWIN64, Created on: Tue Oct 21 15:46:48 2014', '__version__': '1.0', '__globals__': [], 'fea': array([[1, 2, 1, ..., 2, 2, 1],\n",
      "       [3, 3, 4, ..., 1, 3, 4],\n",
      "       [4, 1, 4, ..., 2, 4, 4],\n",
      "       ...,\n",
      "       [3, 4, 4, ..., 3, 1, 2],\n",
      "       [1, 4, 3, ..., 4, 3, 4],\n",
      "       [4, 3, 1, ..., 2, 4, 3]], dtype=uint8), 'gnd': array([[1],\n",
      "       [1],\n",
      "       [1],\n",
      "       ...,\n",
      "       [1],\n",
      "       [1],\n",
      "       [1]], dtype=int16)}\n"
     ]
    }
   ],
   "source": [
    "# DataA.mat\n",
    "print(\"Dataset A: \\n\", mat_dataA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Features from the matrix \n",
    "mat_features_datA = mat_dataA['fea']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Labels from the Matrix \n",
    "mat_label_dataA = mat_dataA['gnd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features from the Dataset: \n",
      "       0   1   2   3   4   5   6   7   8   9   ...  47  48  49  50  51  52  53  \\\n",
      "0      1   2   1   2   1   2   3   3   3   3  ...   4   3   2   3   4   2   2   \n",
      "1      3   3   4   2   1   2   2   4   3   2  ...   3   1   4   3   4   4   4   \n",
      "2      4   1   4   4   4   4   1   1   2   1  ...   1   1   2   1   1   4   2   \n",
      "3      1   4   1   1   3   3   4   4   3   4  ...   2   1   3   3   4   1   3   \n",
      "4      3   4   4   3   1   1   4   4   4   1  ...   4   3   1   3   2   1   4   \n",
      "...   ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ..  ..  ..  ..  ..  ..  ..   \n",
      "2195   3   3   3   4   2   2   3   3   4   4  ...   2   1   4   3   3   4   1   \n",
      "2196   3   3   1   1   2   3   3   4   3   1  ...   4   2   1   3   1   2   3   \n",
      "2197   3   4   4   3   3   3   1   2   4   3  ...   2   4   3   3   4   1   2   \n",
      "2198   1   4   3   4   1   3   4   2   4   3  ...   4   2   4   2   2   2   4   \n",
      "2199   4   3   1   2   2   3   3   3   3   4  ...   3   4   3   3   4   3   4   \n",
      "\n",
      "      54  55  56  \n",
      "0      2   2   1  \n",
      "1      1   3   4  \n",
      "2      2   4   4  \n",
      "3      3   4   2  \n",
      "4      2   1   1  \n",
      "...   ..  ..  ..  \n",
      "2195   2   1   3  \n",
      "2196   4   2   3  \n",
      "2197   3   1   2  \n",
      "2198   4   3   4  \n",
      "2199   2   4   3  \n",
      "\n",
      "[2200 rows x 57 columns]\n"
     ]
    }
   ],
   "source": [
    "# Convert the Feature Matrix data into Pandas Dataframe\n",
    "df_features_dataA = pd.DataFrame(mat_features_datA)\n",
    "print(\"Features from the Dataset: \\n\", df_features_dataA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                0            1            2            3            4   \\\n",
      "count  2200.000000  2200.000000  2200.000000  2200.000000  2200.000000   \n",
      "mean      2.493182     2.529545     2.506818     2.526818     2.547727   \n",
      "std       1.103943     1.086542     1.098160     1.118780     1.081699   \n",
      "min       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
      "25%       2.000000     2.000000     2.000000     2.000000     2.000000   \n",
      "50%       3.000000     3.000000     3.000000     3.000000     3.000000   \n",
      "75%       3.000000     3.000000     3.000000     4.000000     3.000000   \n",
      "max       4.000000     4.000000     4.000000     4.000000     4.000000   \n",
      "\n",
      "                5            6            7            8           9   ...  \\\n",
      "count  2200.000000  2200.000000  2200.000000  2200.000000  2200.00000  ...   \n",
      "mean      2.492727     2.550000     2.541364     2.553182     2.56500  ...   \n",
      "std       1.099399     1.109818     1.103600     1.126751     1.10822  ...   \n",
      "min       1.000000     1.000000     1.000000     1.000000     1.00000  ...   \n",
      "25%       2.000000     2.000000     2.000000     2.000000     2.00000  ...   \n",
      "50%       3.000000     3.000000     3.000000     3.000000     3.00000  ...   \n",
      "75%       3.000000     4.000000     3.000000     4.000000     4.00000  ...   \n",
      "max       4.000000     4.000000     4.000000     4.000000     4.00000  ...   \n",
      "\n",
      "                47           48           49           50           51  \\\n",
      "count  2200.000000  2200.000000  2200.000000  2200.000000  2200.000000   \n",
      "mean      2.475000     2.498636     2.497273     2.439091     2.495909   \n",
      "std       1.070635     1.104786     1.070499     1.093583     1.087354   \n",
      "min       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
      "25%       2.000000     2.000000     2.000000     1.000000     2.000000   \n",
      "50%       2.000000     3.000000     2.000000     2.000000     2.000000   \n",
      "75%       3.000000     3.000000     3.000000     3.000000     3.000000   \n",
      "max       4.000000     4.000000     4.000000     4.000000     4.000000   \n",
      "\n",
      "                52           53           54           55           56  \n",
      "count  2200.000000  2200.000000  2200.000000  2200.000000  2200.000000  \n",
      "mean      2.482273     2.435909     2.500455     2.456364     2.512273  \n",
      "std       1.065672     1.089652     1.091952     1.093162     1.086456  \n",
      "min       1.000000     1.000000     1.000000     1.000000     1.000000  \n",
      "25%       2.000000     1.000000     2.000000     2.000000     2.000000  \n",
      "50%       2.000000     2.000000     3.000000     2.000000     3.000000  \n",
      "75%       3.000000     3.000000     3.000000     3.000000     3.000000  \n",
      "max       4.000000     4.000000     4.000000     4.000000     4.000000  \n",
      "\n",
      "[8 rows x 57 columns]\n"
     ]
    }
   ],
   "source": [
    "# Statistical Description of the Dataset\n",
    "print(df_features_dataA.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check For Missing Values in the Dataset  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Missing Values in the Dataset:  0\n"
     ]
    }
   ],
   "source": [
    "# Number of Missing Values in the Dataset \n",
    "print(\"Total Number of Missing Values in the Dataset: \",df_features_dataA.isna().sum().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### There are no missing values in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Unique Lables in the Dataset:  [ 1 -1]\n"
     ]
    }
   ],
   "source": [
    "# Convert the Labels to Dataframe and Check for Unique Values \n",
    "df_label_dataA = pd.DataFrame(mat_label_dataA)\n",
    "print(\"Number of Unique Lables in the Dataset: \", df_label_dataA[0].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### There are two unique labels in the data set -1 and 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1.1: - Z-Score Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z-Score Normalization\n",
    "ss = StandardScaler()\n",
    "ss.fit(df_features_dataA)\n",
    "z_standardized_dataA = ss.transform(df_features_dataA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardised DataA: \n",
      " [[-1.35289759 -0.48747864 -1.37244139 ... -0.4584159  -0.41756618\n",
      "  -1.39224875]\n",
      " [ 0.45920268  0.43308188  1.36002111 ... -1.37441497  0.49741947\n",
      "   1.36965138]\n",
      " [ 1.36525282 -1.40803915  1.36002111 ... -0.4584159   1.41240513\n",
      "   1.36965138]\n",
      " ...\n",
      " [ 0.45920268  1.35364239  1.36002111 ...  0.45758317 -1.33255183\n",
      "  -0.47161537]\n",
      " [-1.35289759  1.35364239  0.44920027 ...  1.37358225  0.49741947\n",
      "   1.36965138]\n",
      " [ 1.36525282  0.43308188 -1.37244139 ... -0.4584159   1.41240513\n",
      "   0.44901801]]\n"
     ]
    }
   ],
   "source": [
    "# Standardised Dataset \n",
    "print(\"Standardised DataA: \\n\",z_standardized_dataA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converted array is : [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "# Convert Labels to numpy array\n",
    "np_label_dataA = df_label_dataA.to_numpy()\n",
    "print(\"converted array is :\",np_label_dataA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomnly spliting the data 70% of samples for taining and other 30% for testing\n",
    "### using hold-out scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " Features for Train Dataset: \n",
      " [[ 1.36525282 -0.48747864  0.44920027 ...  1.37358225  1.41240513\n",
      "   1.36965138]\n",
      " [-0.44684745 -0.48747864 -1.37244139 ...  1.37358225 -1.33255183\n",
      "   1.36965138]\n",
      " [-0.44684745  1.35364239 -1.37244139 ...  0.45758317 -1.33255183\n",
      "   0.44901801]\n",
      " ...\n",
      " [ 1.36525282 -0.48747864 -0.46162056 ... -0.4584159  -0.41756618\n",
      "   0.44901801]\n",
      " [ 0.45920268  0.43308188  0.44920027 ... -1.37441497  0.49741947\n",
      "   0.44901801]\n",
      " [-0.44684745  1.35364239 -0.46162056 ... -1.37441497 -0.41756618\n",
      "  -0.47161537]]\n",
      " \n",
      " Labels for the Train Dataset: \n",
      " [ 1  1 -1 ... -1 -1  1]\n"
     ]
    }
   ],
   "source": [
    "# Split the Dataset using Train Test Split \n",
    "x_train_dataA, x_test_dataA, y_train_dataA, y_test_dataA = train_test_split(z_standardized_dataA,np_label_dataA.ravel(),test_size = 0.3, random_state = 42)\n",
    "\n",
    "print(\" \\n Features for Train Dataset: \\n\", x_train_dataA)\n",
    "print(\" \\n Labels for the Train Dataset: \\n\", y_train_dataA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The hold out method is kind of cross validation method where the dataset is split into training and test set. Later the model is trained on only traning set and then output values are predicted using the same model for the Test set. \n",
    "\n",
    "#### Advantages:\n",
    "Easier to compute\n",
    "\n",
    "#### Disadvantage:\n",
    "1. Sometimes evaluation has higher variance\n",
    "2. It depends on what datapoints are in test set and what in training set so it depends on split heavily."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1.2: 5-fold Cross Validation on Training set to select the Parameters k for k_NN from given set and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set of parameters for k value is: \n",
      " [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31]\n"
     ]
    }
   ],
   "source": [
    "# Create a list for k from 1 to 31 \n",
    "k_list=list(range(1,32,2))\n",
    "print(\"Set of parameters for k value is: \\n\",k_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k: 1, Accuracies: [0.69805195 0.69805195 0.69155844 0.72077922 0.72402597]\n",
      "For k: 3, Accuracies: [0.7012987  0.73376623 0.70779221 0.73701299 0.71753247]\n",
      "For k: 5, Accuracies: [0.72727273 0.73376623 0.75324675 0.72402597 0.71103896]\n",
      "For k: 7, Accuracies: [0.73701299 0.74675325 0.73376623 0.73051948 0.7012987 ]\n",
      "For k: 9, Accuracies: [0.74675325 0.75324675 0.73701299 0.72402597 0.69805195]\n",
      "For k: 11, Accuracies: [0.75649351 0.76298701 0.71103896 0.73051948 0.69805195]\n",
      "For k: 13, Accuracies: [0.73701299 0.77272727 0.71103896 0.74350649 0.71428571]\n",
      "For k: 15, Accuracies: [0.72727273 0.75324675 0.73376623 0.75324675 0.72077922]\n",
      "For k: 17, Accuracies: [0.72077922 0.75       0.72727273 0.76298701 0.71428571]\n",
      "For k: 19, Accuracies: [0.72077922 0.73701299 0.72077922 0.75       0.70454545]\n",
      "For k: 21, Accuracies: [0.71103896 0.75       0.70779221 0.75974026 0.69805195]\n",
      "For k: 23, Accuracies: [0.68831169 0.75       0.71103896 0.76623377 0.71103896]\n",
      "For k: 25, Accuracies: [0.69155844 0.75974026 0.71428571 0.74350649 0.71103896]\n",
      "For k: 27, Accuracies: [0.69155844 0.76298701 0.71753247 0.74025974 0.7012987 ]\n",
      "For k: 29, Accuracies: [0.69805195 0.74025974 0.71428571 0.73701299 0.71103896]\n",
      "For k: 31, Accuracies: [0.69805195 0.74350649 0.70454545 0.73376623 0.71103896]\n",
      "Mean of accuracy scores: \n",
      " [0.7064935064935064, 0.7194805194805195, 0.7298701298701299, 0.7298701298701298, 0.7318181818181817, 0.7318181818181817, 0.7357142857142858, 0.7376623376623377, 0.7350649350649351, 0.7266233766233767, 0.7253246753246754, 0.7253246753246754, 0.724025974025974, 0.7227272727272728, 0.7201298701298702, 0.7181818181818181]\n"
     ]
    }
   ],
   "source": [
    "# empty list to store accuracy\n",
    "K_accuracy=[]\n",
    "\n",
    "# looping through given values of k\n",
    "for k in k_list:\n",
    "    # 2. KNeighborsClassifier with k neighbours\n",
    "    knn = KNeighborsClassifier(n_neighbors = k)\n",
    "    # 3. cross_val_score for KNeighborsClassifier with k neighbours\n",
    "    accuracy = cross_val_score(knn, x_train_dataA, y_train_dataA, cv=5, scoring = 'accuracy')\n",
    "    print(\"For k: {0}, Accuracies: {1}\".format(k, accuracy))\n",
    "    #4. append mean of scores for k neighbours to k_accuracy list\n",
    "    K_accuracy.append(accuracy.mean())\n",
    "\n",
    "print(\"Mean of accuracy scores: \\n\", K_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(k_list, K_accuracy, label = 'Accuracy')\n",
    "plt.xlabel('Value of K for KNN (K) ')\n",
    "plt.ylabel('Cross-validated Accuracy')\n",
    "plt.title('Relationship between Accuracy and Parameter K')\n",
    "plt.legend(loc = 'best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best Calculation accuracy is : 0.7376623376623377\n"
     ]
    }
   ],
   "source": [
    "# Get the Maximum Value of Accuracy Score \n",
    "print('The best Calculation accuracy is :' , max(K_accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Best Calculation accuracy of 0.7376623376623377 ie. 73.77% is best for value of K = 15\n",
    "\n",
    "#### Hence the Best K in term of Classification Accuracy is 15. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1.3: RBF Kernel best parameter selection in terms of classification accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dicitionary of Parameters C and Gamma: \n",
      "  {'C': [0.1, 0.5, 1, 2, 5, 10, 20, 50], 'gamma': [0.01, 0.05, 0.1, 0.5, 1, 2, 5, 10]}\n"
     ]
    }
   ],
   "source": [
    "# Dicitionary of Parameters C and Gamma\n",
    "c = [0.1, 0.5, 1, 2, 5, 10, 20, 50]\n",
    "gamma = [0.01, 0.05 , 0.1, 0.5, 1, 2, 5, 10]\n",
    "param_dict = dict(C = c, gamma = gamma)\n",
    "print(\"Dicitionary of Parameters C and Gamma: \\n \",param_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data fitted with best parameters \n",
    "clf = svm.SVC(kernel = 'rbf')\n",
    "search = GridSearchCV(clf, param_dict, cv = 5, scoring = 'accuracy').fit(x_train_dataA, y_train_dataA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Best Score from Grid Search:  0.9045454545454547\n"
     ]
    }
   ],
   "source": [
    "# Best Score for the Search \n",
    "print(\" Best Score from Grid Search: \",search.best_score_)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters from the Grid Search: \n",
      " {'C': 10, 'gamma': 0.01}\n"
     ]
    }
   ],
   "source": [
    "# Best Parameters from the Grid Search \n",
    "print(\"Best Parameters from the Grid Search: \\n\", search.best_params_)\n",
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The best parameters are : The best Soft Margin penality 'c' is 10 and gamma is 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1.4:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Test Set: \n",
      " [[ 1.36525282 -0.48747864 -0.46162056 ... -1.37441497 -0.41756618\n",
      "   0.44901801]\n",
      " [-1.35289759  1.35364239 -1.37244139 ...  1.37358225  0.49741947\n",
      "  -1.39224875]\n",
      " [ 0.45920268  0.43308188  1.36002111 ...  1.37358225  1.41240513\n",
      "   0.44901801]\n",
      " ...\n",
      " [ 1.36525282 -1.40803915  1.36002111 ...  1.37358225 -0.41756618\n",
      "   1.36965138]\n",
      " [ 0.45920268  1.35364239  0.44920027 ...  1.37358225  1.41240513\n",
      "   0.44901801]\n",
      " [ 1.36525282  1.35364239  0.44920027 ...  0.45758317  1.41240513\n",
      "   0.44901801]]\n",
      "Label Test Set: \n",
      " [-1  1  1 -1  1 -1  1 -1 -1 -1 -1 -1  1  1  1 -1  1  1  1 -1 -1  1 -1 -1\n",
      " -1  1  1  1  1 -1  1 -1 -1  1 -1 -1 -1  1 -1 -1  1 -1  1 -1  1  1 -1 -1\n",
      "  1 -1  1  1  1 -1  1 -1  1  1  1 -1  1  1 -1 -1 -1  1 -1 -1  1  1  1 -1\n",
      " -1 -1  1  1  1  1 -1  1  1  1  1 -1 -1  1  1 -1 -1 -1 -1  1  1  1 -1 -1\n",
      "  1  1 -1  1  1 -1  1  1  1 -1  1 -1 -1  1 -1  1 -1  1  1 -1  1 -1  1 -1\n",
      "  1 -1 -1  1  1  1 -1 -1  1 -1  1 -1 -1 -1 -1  1  1  1  1  1  1  1  1 -1\n",
      "  1  1  1  1  1  1 -1 -1 -1  1 -1  1  1 -1 -1  1  1  1 -1  1  1 -1 -1 -1\n",
      "  1  1 -1  1  1  1 -1  1 -1 -1 -1 -1 -1 -1  1 -1  1 -1  1  1  1 -1 -1  1\n",
      " -1  1  1  1  1  1 -1  1  1  1 -1 -1 -1  1 -1  1 -1 -1  1  1  1  1 -1 -1\n",
      " -1 -1 -1  1 -1 -1  1 -1  1 -1  1 -1  1 -1  1  1 -1  1  1 -1  1 -1 -1  1\n",
      " -1 -1  1 -1  1  1  1  1 -1  1  1 -1 -1  1  1  1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1  1 -1  1  1 -1  1  1 -1 -1  1 -1  1 -1 -1 -1  1  1 -1  1 -1 -1\n",
      "  1 -1  1  1  1  1 -1 -1 -1 -1  1 -1  1  1 -1 -1  1  1  1 -1 -1 -1  1  1\n",
      " -1 -1 -1 -1  1  1 -1  1  1 -1  1 -1  1  1 -1 -1  1  1  1 -1  1  1  1 -1\n",
      " -1 -1 -1  1 -1 -1  1  1  1  1  1  1  1 -1 -1  1 -1 -1  1 -1 -1  1 -1  1\n",
      "  1 -1  1  1  1 -1  1 -1 -1  1  1 -1  1 -1 -1 -1 -1 -1 -1 -1  1 -1  1 -1\n",
      " -1  1 -1  1  1 -1 -1 -1  1 -1  1  1  1  1  1 -1 -1  1 -1  1 -1 -1  1  1\n",
      " -1  1 -1 -1  1  1  1 -1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1  1 -1 -1\n",
      " -1 -1 -1 -1 -1  1 -1  1  1  1 -1 -1  1  1 -1 -1 -1 -1 -1  1 -1  1  1  1\n",
      "  1 -1 -1 -1 -1 -1 -1  1  1 -1 -1  1 -1 -1 -1  1  1 -1  1 -1 -1 -1 -1  1\n",
      " -1  1 -1  1 -1  1 -1 -1  1  1 -1 -1  1  1  1 -1  1  1  1 -1  1  1  1 -1\n",
      " -1 -1  1  1 -1 -1  1 -1  1  1 -1  1  1 -1 -1 -1  1  1  1  1  1 -1 -1 -1\n",
      " -1 -1  1  1  1 -1 -1  1 -1  1  1  1 -1 -1  1 -1 -1 -1  1  1 -1 -1  1  1\n",
      "  1 -1 -1 -1 -1 -1  1  1 -1 -1  1 -1  1  1 -1  1  1 -1 -1  1  1 -1 -1  1\n",
      "  1  1 -1  1 -1 -1  1 -1 -1 -1  1 -1  1 -1 -1  1 -1  1 -1 -1 -1 -1 -1  1\n",
      "  1 -1  1 -1  1 -1 -1 -1  1  1  1  1 -1 -1  1 -1  1  1  1 -1 -1 -1  1  1\n",
      "  1  1  1 -1  1  1 -1 -1 -1 -1  1  1 -1 -1  1 -1 -1  1  1  1  1 -1  1  1\n",
      " -1 -1 -1  1 -1 -1 -1  1 -1  1 -1  1]\n"
     ]
    }
   ],
   "source": [
    "# Feature Test set and Label Test Set \n",
    "print(\"Feature Test Set: \\n\",x_test_dataA)\n",
    "print(\"Label Test Set: \\n\",y_test_dataA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is : 0.75\n",
      "Precision is : 0.9202127659574468\n",
      "Recall is : 0.5356037151702786\n",
      "F1-Score is : 0.6771037181996086\n"
     ]
    }
   ],
   "source": [
    "# For K-NN using above parameters to classify the test set \n",
    "# k = 15 gave best classification accuracy\n",
    "\n",
    "Knn_model = KNeighborsClassifier(n_neighbors = 15)\n",
    "Knn_model.fit(x_train_dataA,y_train_dataA)\n",
    "\n",
    "y_pred_KNN = Knn_model.predict(x_test_dataA)\n",
    "\n",
    "# comparison between actual and predicted response\n",
    "print(\"Accuracy is :\",metrics.accuracy_score(y_test_dataA, y_pred_KNN))\n",
    "print(\"Precision is :\",metrics.precision_score(y_test_dataA, y_pred_KNN))\n",
    "print(\"Recall is :\",metrics.recall_score(y_test_dataA, y_pred_KNN))\n",
    "print(\"F1-Score is :\",metrics.f1_score(y_test_dataA, y_pred_KNN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for KNN: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.68      0.96      0.80       337\n",
      "           1       0.92      0.54      0.68       323\n",
      "\n",
      "    accuracy                           0.75       660\n",
      "   macro avg       0.80      0.75      0.74       660\n",
      "weighted avg       0.80      0.75      0.74       660\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification Report for Each Class for KNN\n",
    "print(\"Classification Report for KNN: \\n\", classification_report(y_test_dataA, y_pred_KNN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is : 0.9075757575757576\n",
      "Precision is : 0.9145569620253164\n",
      "Recall is : 0.8947368421052632\n",
      "F1-Score is : 0.9045383411580594\n"
     ]
    }
   ],
   "source": [
    "# For SVM using above parameters to classify the test set\n",
    "SVN_model = SVC(C = 10,gamma = 0.01)\n",
    "SVN_model.fit(x_train_dataA,y_train_dataA)\n",
    "\n",
    "y_pred_SVN = SVN_model.predict(x_test_dataA)\n",
    "\n",
    "# comparison between actual and predicted response\n",
    "print(\"Accuracy is :\",metrics.accuracy_score(y_test_dataA, y_pred_SVN))\n",
    "print(\"Precision is :\",metrics.precision_score(y_test_dataA, y_pred_SVN))\n",
    "print(\"Recall is :\",metrics.recall_score(y_test_dataA, y_pred_SVN))\n",
    "print(\"F1-Score is :\",metrics.f1_score(y_test_dataA, y_pred_SVN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for SVM: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.90      0.92      0.91       337\n",
      "           1       0.91      0.89      0.90       323\n",
      "\n",
      "    accuracy                           0.91       660\n",
      "   macro avg       0.91      0.91      0.91       660\n",
      "weighted avg       0.91      0.91      0.91       660\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification Report for Each Class for SVM\n",
    "print(\"Classification Report for SVM: \\n\", classification_report(y_test_dataA, y_pred_SVN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is : 0.8818181818181818\n",
      "Precision is : 0.8792569659442725\n",
      "Recall is : 0.8792569659442725\n",
      "F1-Score is : 0.8792569659442725\n"
     ]
    }
   ],
   "source": [
    "# Using default setups for Naive Bayes Classifier to classify test set\n",
    "NB_model = GaussianNB()\n",
    "NB_model.fit(x_train_dataA,y_train_dataA)\n",
    "\n",
    "y_pred_NB = NB_model.predict(x_test_dataA)\n",
    "\n",
    "# comparison between actual and predicted response\n",
    "print(\"Accuracy is :\",metrics.accuracy_score(y_test_dataA, y_pred_NB))\n",
    "print(\"Precision is :\",metrics.precision_score(y_test_dataA, y_pred_NB))\n",
    "print(\"Recall is :\",metrics.recall_score(y_test_dataA, y_pred_NB))\n",
    "print(\"F1-Score is :\",metrics.f1_score(y_test_dataA, y_pred_NB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for  Gaussian Naive Bayes: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.88      0.88      0.88       337\n",
      "           1       0.88      0.88      0.88       323\n",
      "\n",
      "    accuracy                           0.88       660\n",
      "   macro avg       0.88      0.88      0.88       660\n",
      "weighted avg       0.88      0.88      0.88       660\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification Report for Each Class for Gaussian Naive Bayes\n",
    "print(\"Classification Report for  Gaussian Naive Bayes: \\n\", classification_report(y_test_dataA, y_pred_NB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is : 0.9272727272727272\n",
      "Precision is : 0.9310344827586207\n",
      "Recall is : 0.9195046439628483\n",
      "F1-Score is : 0.9252336448598131\n"
     ]
    }
   ],
   "source": [
    "# Using default setups for Decision Trees to classify test set\n",
    "DT_model = DecisionTreeClassifier()\n",
    "DT_model.fit(x_train_dataA,y_train_dataA)\n",
    "\n",
    "y_pred_DT = DT_model.predict(x_test_dataA)\n",
    "\n",
    "# comparison between actual and predicted response\n",
    "print(\"Accuracy is :\",metrics.accuracy_score(y_test_dataA, y_pred_DT))\n",
    "print(\"Precision is :\",metrics.precision_score(y_test_dataA, y_pred_DT))\n",
    "print(\"Recall is :\",metrics.recall_score(y_test_dataA, y_pred_DT))\n",
    "print(\"F1-Score is :\",metrics.f1_score(y_test_dataA, y_pred_DT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Decision Trees: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.92      0.93      0.93       337\n",
      "           1       0.93      0.92      0.93       323\n",
      "\n",
      "    accuracy                           0.93       660\n",
      "   macro avg       0.93      0.93      0.93       660\n",
      "weighted avg       0.93      0.93      0.93       660\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification Report for Each Class for Decision Trees\n",
    "print(\"Classification Report for Decision Trees: \\n\", classification_report(y_test_dataA, y_pred_DT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Classifier with 20 Iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracy list is : [0.7818181818181819, 0.7545454545454545, 0.7227272727272728, 0.759090909090909, 0.7575757575757576, 0.7378787878787879, 0.7803030303030303, 0.75, 0.7272727272727273, 0.7757575757575758, 0.7151515151515152, 0.7045454545454546, 0.7166666666666667, 0.7681818181818182, 0.7439393939393939, 0.7484848484848485, 0.7424242424242424, 0.7242424242424242, 0.7333333333333333, 0.746969696969697, 0.7378787878787879]\n",
      "\n",
      "\n",
      "Precision list is : [0.9748743718592965, 0.9572192513368984, 0.9714285714285714, 0.9637305699481865, 0.9575471698113207, 0.9521276595744681, 0.9660194174757282, 0.9651741293532339, 0.9421052631578948, 0.9690721649484536, 0.9828571428571429, 0.9378531073446328, 0.9662921348314607, 0.9635416666666666, 0.9896907216494846, 0.9567567567567568, 0.9646464646464646, 0.9651162790697675, 0.9606741573033708, 0.9646464646464646, 0.9779005524861878]\n",
      "\n",
      "\n",
      "Recall list is: [0.5825825825825826, 0.5375375375375375, 0.4885057471264368, 0.5502958579881657, 0.5734463276836158, 0.521865889212828, 0.5905044510385756, 0.5511363636363636, 0.514367816091954, 0.5696969696969697, 0.48179271708683474, 0.4742857142857143, 0.48725212464589235, 0.5589123867069486, 0.5348189415041783, 0.5283582089552239, 0.53954802259887, 0.4853801169590643, 0.5029411764705882, 0.5441595441595442, 0.5115606936416185]\n",
      "\n",
      "\n",
      "F1-Score list is: [0.7293233082706767, 0.6884615384615385, 0.6500956022944551, 0.7005649717514124, 0.7173144876325089, 0.6741996233521657, 0.732965009208103, 0.7016274864376131, 0.6654275092936803, 0.717557251908397, 0.6466165413533834, 0.6299810246679318, 0.647834274952919, 0.7074569789674953, 0.6943942133815553, 0.6807692307692309, 0.6920289855072463, 0.6459143968871596, 0.6602316602316602, 0.6958105646630237, 0.6717267552182162]\n",
      "\n",
      " Mean for accuracy in case of KNN is:  0.7442279942279942\n",
      "\n",
      " Standard Deviation for accuracy in case of KNN is:  0.021132705635035186\n",
      "\n",
      "\n",
      "mean for precision list in case of KNN is 0.9642511436739261\n",
      "\n",
      "\n",
      "Standard Deviation for precision list in case of KNN is 0.011700384104702295\n",
      "\n",
      "\n",
      "mean for recall score in case of KNN is 0.5299499614099764\n",
      "\n",
      "\n",
      "Standard Deviation for recall score in case of KNN is 0.03402303748050454\n",
      "\n",
      "\n",
      "mean for f1 score in case of KNN is 0.6833476864385892\n",
      "\n",
      "\n",
      "Standard Deviation for f1 score in case of KNN is 0.02889766938216869\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Repeating above steps 20 times by varying the split of training-test set as in Step 1\n",
    "\n",
    "# for KNN\n",
    "Knn_model2 = KNeighborsClassifier(n_neighbors=15)\n",
    "# Classification based on KNN\n",
    "random_seed_iterations = range(1,42,2)\n",
    "KNN_accuracy_list=[] \n",
    "KNN_precision_list=[]\n",
    "KNN_recall_list=[]\n",
    "KNN_f1_list=[]\n",
    "\n",
    "# Iteration for Retraining\n",
    "for i in random_seed_iterations:\n",
    "\n",
    "    # Random Dataset Split\n",
    "    x_train_dataA_KNN, x_test_dataA_KNN, y_train_dataA_KNN, y_test_dataA_KNN = train_test_split(z_standardized_dataA,np_label_dataA.ravel(),test_size =0.3, random_state = i)\n",
    "\n",
    "    # Training the Model\n",
    "    Knn_model2.fit(x_train_dataA_KNN, y_train_dataA_KNN)\n",
    "\n",
    "    # Test Dataset Prediction\n",
    "    y_predict_KNN_list = Knn_model2.predict(x_test_dataA_KNN)\n",
    "    \n",
    "    # Classification Accuracy\n",
    "    accuracy = metrics.accuracy_score(y_test_dataA_KNN, y_predict_KNN_list)\n",
    "    KNN_accuracy_list.append(accuracy)\n",
    "    \n",
    "    # Precision\n",
    "    precision = metrics.precision_score(y_test_dataA_KNN, y_predict_KNN_list)\n",
    "    KNN_precision_list.append(precision)\n",
    "                                    \n",
    "    # Recall\n",
    "    recall = metrics.recall_score(y_test_dataA_KNN, y_predict_KNN_list)\n",
    "    KNN_recall_list.append(recall)\n",
    "    \n",
    "    # F1-score\n",
    "    f1score = metrics.f1_score(y_test_dataA_KNN, y_predict_KNN_list)\n",
    "    KNN_f1_list.append(f1score)\n",
    "\n",
    "\n",
    "print(\"Acuracy list is :\",KNN_accuracy_list)\n",
    "print(\"\\n\")\n",
    "print(\"Precision list is :\",KNN_precision_list)\n",
    "print(\"\\n\")\n",
    "print(\"Recall list is:\",KNN_recall_list)\n",
    "print(\"\\n\")\n",
    "print(\"F1-Score list is:\",KNN_f1_list)\n",
    "\n",
    "# Average and standard Deviation of Classification values\n",
    "\n",
    "mean_accuracy_list_KNN = sum(KNN_accuracy_list)/len(KNN_accuracy_list)\n",
    "variance_accuracy_list_KNN = sum([((x-mean_accuracy_list_KNN)**2) for x in KNN_accuracy_list])/len(KNN_accuracy_list)\n",
    "sd_accuracy_list_KNN = variance_accuracy_list_KNN**0.5\n",
    "\n",
    "print(\"\\n Mean for accuracy in case of KNN is: \",mean_accuracy_list_KNN)\n",
    "print(\"\\n Standard Deviation for accuracy in case of KNN is: \",sd_accuracy_list_KNN)\n",
    "print(\"\\n\")\n",
    "\n",
    "mean_precision_list_KNN=sum(KNN_precision_list)/len(KNN_precision_list)\n",
    "variance_precision_list_KNN=sum([((x-mean_precision_list_KNN)**2) for x in KNN_precision_list])/len(KNN_precision_list)\n",
    "sd_precision_list_KNN=variance_precision_list_KNN**0.5\n",
    "\n",
    "print(\"mean for precision list in case of KNN is\",mean_precision_list_KNN)\n",
    "print(\"\\n\")\n",
    "print(\"Standard Deviation for precision list in case of KNN is\",sd_precision_list_KNN)\n",
    "print(\"\\n\")\n",
    "\n",
    "mean_recall_score_list_KNN=sum(KNN_recall_list)/len(KNN_recall_list)\n",
    "variance_recall_score_list_KNN=sum([((x-mean_recall_score_list_KNN)**2) for x in KNN_recall_list])/len(KNN_recall_list)\n",
    "sd_recall_score_list_KNN=variance_recall_score_list_KNN**0.5\n",
    "\n",
    "print(\"mean for recall score in case of KNN is\",mean_recall_score_list_KNN)\n",
    "print(\"\\n\")\n",
    "print(\"Standard Deviation for recall score in case of KNN is\",sd_recall_score_list_KNN)\n",
    "print(\"\\n\")\n",
    "\n",
    "mean_f1_score_list_KNN=sum(KNN_f1_list)/len(KNN_f1_list)\n",
    "variance_f1_score_list_KNN=sum([((x-mean_f1_score_list_KNN)**2) for x in KNN_f1_list])/len(KNN_f1_list)\n",
    "sd_f1_score_list_KNN=variance_f1_score_list_KNN**0.5\n",
    "\n",
    "print(\"mean for f1 score in case of KNN is\",mean_f1_score_list_KNN)\n",
    "print(\"\\n\")\n",
    "print(\"Standard Deviation for f1 score in case of KNN is\",sd_f1_score_list_KNN)\n",
    "print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Classifier with 20 Iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracy list is : [0.9227272727272727, 0.9121212121212121, 0.9121212121212121, 0.9075757575757576, 0.9, 0.8742424242424243, 0.8939393939393939, 0.9181818181818182, 0.906060606060606, 0.9136363636363637, 0.8893939393939394, 0.8893939393939394, 0.9090909090909091, 0.9166666666666666, 0.9196969696969697, 0.9136363636363637, 0.9075757575757576, 0.9, 0.8954545454545455, 0.9045454545454545, 0.9106060606060606]\n",
      "\n",
      "\n",
      "Precision list is : [0.937888198757764, 0.8962536023054755, 0.9289940828402367, 0.9287925696594427, 0.9022346368715084, 0.8846153846153846, 0.8985074626865671, 0.9408284023668639, 0.9255952380952381, 0.9174311926605505, 0.9303030303030303, 0.9134328358208955, 0.9347181008902077, 0.9394904458598726, 0.9371428571428572, 0.9237804878048781, 0.9197707736389685, 0.8942857142857142, 0.9118541033434651, 0.9285714285714286, 0.9309309309309309]\n",
      "\n",
      "\n",
      "Recall list is: [0.9069069069069069, 0.933933933933934, 0.9022988505747126, 0.8875739644970414, 0.9124293785310734, 0.8717201166180758, 0.8931750741839762, 0.9034090909090909, 0.8936781609195402, 0.9090909090909091, 0.8599439775910365, 0.8742857142857143, 0.8923512747875354, 0.8912386706948641, 0.9136490250696379, 0.9044776119402985, 0.9067796610169492, 0.9152046783625731, 0.8823529411764706, 0.8888888888888888, 0.8959537572254336]\n",
      "\n",
      "\n",
      "F1-Score list is: [0.9221374045801528, 0.9147058823529413, 0.9154518950437318, 0.9077155824508321, 0.9073033707865168, 0.8781204111600587, 0.8958333333333333, 0.9217391304347827, 0.9093567251461988, 0.9132420091324202, 0.8937409024745271, 0.8934306569343066, 0.9130434782608695, 0.9147286821705426, 0.9252468265162199, 0.914027149321267, 0.9132290184921764, 0.9046242774566474, 0.8968609865470851, 0.9082969432314411, 0.9131075110456554]\n",
      "\n",
      "\n",
      "mean for accuracy in case of SVM is:  0.9055555555555556\n",
      "\n",
      "\n",
      "Standard Deviation for accuracy in case of SVM is:  0.011636533989453692\n",
      "\n",
      "\n",
      "mean for precision list in case of SVM is 0.9202581656881561\n",
      "\n",
      "\n",
      "Standard Deviation for precision list in case of SVM is 0.01620781017136178\n",
      "\n",
      "\n",
      "mean for recall score in case of SVM is 0.8971115517716507\n",
      "\n",
      "\n",
      "Standard Deviation for recall score in case of SVM is 0.01640915447683593\n",
      "\n",
      "\n",
      "mean for f1 score in case of SVM is 0.9083781988986527\n",
      "\n",
      "\n",
      "Standard Deviation for f1 score in case of SVM is 0.011053761601686089\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For SVM\n",
    "SVM_model2 = SVC(C = 10,gamma = 0.01)\n",
    "\n",
    "# Classification based on SVM\n",
    "SVM_accuracy_list=[]\n",
    "SVM_precision_list=[]\n",
    "SVM_recall_list=[]\n",
    "SVM_f1_list=[]\n",
    "\n",
    "# Iteration for Retraining\n",
    "for i in random_seed_iterations:\n",
    "    # Random Dataset Split\n",
    "    x_train_dataA_SVM, x_test_dataA_SVM, y_train_dataA_SVM, y_test_dataA_SVM = train_test_split(z_standardized_dataA, np_label_dataA.ravel(), test_size =0.3, random_state = i)\n",
    "    # Training the Model\n",
    "    SVM_model2.fit(x_train_dataA_SVM, y_train_dataA_SVM)\n",
    "\n",
    "    # Test Dataset Prediction\n",
    "    y_predict_SVM_list = SVM_model2.predict(x_test_dataA_SVM)\n",
    "\n",
    "    # Classification Accuracy\n",
    "    accuracy = metrics.accuracy_score(y_test_dataA_SVM, y_predict_SVM_list)\n",
    "    SVM_accuracy_list.append(accuracy)\n",
    "    \n",
    "    #Precision\n",
    "    precision = metrics.precision_score(y_test_dataA_SVM, y_predict_SVM_list)\n",
    "    SVM_precision_list.append(precision)\n",
    "                                    \n",
    "    #Recall\n",
    "    recall = metrics.recall_score(y_test_dataA_SVM, y_predict_SVM_list)\n",
    "    SVM_recall_list.append(recall)\n",
    "    \n",
    "    #F1-score\n",
    "    f1score = metrics.f1_score(y_test_dataA_SVM, y_predict_SVM_list)\n",
    "    SVM_f1_list.append(f1score)\n",
    "\n",
    "print(\"Acuracy list is :\",SVM_accuracy_list)\n",
    "print(\"\\n\")\n",
    "print(\"Precision list is :\",SVM_precision_list)\n",
    "print(\"\\n\")\n",
    "print(\"Recall list is:\",SVM_recall_list)\n",
    "print(\"\\n\")\n",
    "print(\"F1-Score list is:\",SVM_f1_list)\n",
    "print(\"\\n\")\n",
    "\n",
    "#Average and standard Deviation of Classification values\n",
    "mean_accuracy_list_SVM = sum(SVM_accuracy_list)/len(SVM_accuracy_list)\n",
    "variance_accuracy_list_SVM = sum([((x-mean_accuracy_list_SVM)**2) for x in SVM_accuracy_list])/len(SVM_accuracy_list)\n",
    "sd_accuracy_list_SVM = variance_accuracy_list_SVM**0.5\n",
    "\n",
    "print(\"mean for accuracy in case of SVM is: \",mean_accuracy_list_SVM)\n",
    "print(\"\\n\")\n",
    "print(\"Standard Deviation for accuracy in case of SVM is: \",sd_accuracy_list_SVM)\n",
    "print(\"\\n\")\n",
    "mean_precision_list_SVM=sum(SVM_precision_list)/len(SVM_precision_list)\n",
    "variance_precision_list_SVM=sum([((x-mean_precision_list_SVM)**2) for x in SVM_precision_list])/len(SVM_precision_list)\n",
    "sd_precision_list_SVM=variance_precision_list_SVM**0.5\n",
    "\n",
    "print(\"mean for precision list in case of SVM is\",mean_precision_list_SVM)\n",
    "print(\"\\n\")\n",
    "print(\"Standard Deviation for precision list in case of SVM is\",sd_precision_list_SVM)\n",
    "print(\"\\n\")\n",
    "\n",
    "mean_recall_score_list_SVM=sum(SVM_recall_list)/len(SVM_recall_list)\n",
    "variance_recall_score_list_SVM=sum([((x-mean_recall_score_list_SVM)**2) for x in SVM_recall_list])/len(SVM_recall_list)\n",
    "sd_recall_score_list_SVM=variance_recall_score_list_SVM**0.5\n",
    "\n",
    "print(\"mean for recall score in case of SVM is\",mean_recall_score_list_SVM)\n",
    "print(\"\\n\")\n",
    "print(\"Standard Deviation for recall score in case of SVM is\",sd_recall_score_list_SVM)\n",
    "print(\"\\n\")\n",
    "\n",
    "mean_f1_score_list_SVM=sum(SVM_f1_list)/len(SVM_f1_list)\n",
    "variance_f1_score_list_SVM=sum([((x-mean_f1_score_list_SVM)**2) for x in SVM_f1_list])/len(SVM_f1_list)\n",
    "sd_f1_score_list_SVM=variance_f1_score_list_SVM**0.5\n",
    "\n",
    "print(\"mean for f1 score in case of SVM is\",mean_f1_score_list_SVM)\n",
    "print(\"\\n\")\n",
    "print(\"Standard Deviation for f1 score in case of SVM is\",sd_f1_score_list_SVM)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Classifier with 20 Iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracy list is : [0.8772727272727273, 0.8590909090909091, 0.8787878787878788, 0.8742424242424243, 0.853030303030303, 0.8545454545454545, 0.8712121212121212, 0.8696969696969697, 0.8878787878787879, 0.8727272727272727, 0.8742424242424243, 0.8742424242424243, 0.8590909090909091, 0.8909090909090909, 0.8727272727272727, 0.8681818181818182, 0.8772727272727273, 0.8575757575757575, 0.8469696969696969, 0.8681818181818182, 0.8696969696969697]\n",
      "\n",
      "\n",
      "Precision list is : [0.8539325842696629, 0.835195530726257, 0.8806818181818182, 0.8875379939209727, 0.8599439775910365, 0.8518518518518519, 0.8442622950819673, 0.882183908045977, 0.8914285714285715, 0.8514285714285714, 0.8870056497175142, 0.8803418803418803, 0.8611111111111112, 0.8888888888888888, 0.862796833773087, 0.8583815028901735, 0.8601583113456465, 0.8463687150837989, 0.8385269121813032, 0.8771428571428571, 0.8651685393258427]\n",
      "\n",
      "\n",
      "Recall list is: [0.9129129129129129, 0.8978978978978979, 0.8908045977011494, 0.863905325443787, 0.867231638418079, 0.8717201166180758, 0.9169139465875371, 0.8721590909090909, 0.896551724137931, 0.9030303030303031, 0.8795518207282913, 0.8828571428571429, 0.8781869688385269, 0.8942598187311178, 0.9108635097493036, 0.8865671641791045, 0.9209039548022598, 0.8859649122807017, 0.8705882352941177, 0.8746438746438746, 0.8901734104046243]\n",
      "\n",
      "\n",
      "F1-Score list is: [0.8824383164005805, 0.8654124457308249, 0.8857142857142858, 0.8755622188905547, 0.8635724331926863, 0.861671469740634, 0.8790896159317213, 0.8771428571428572, 0.8939828080229227, 0.8764705882352941, 0.8832630098452883, 0.8815977175463623, 0.8695652173913044, 0.8915662650602408, 0.8861788617886179, 0.8722466960352423, 0.8894952251023192, 0.8657142857142858, 0.8542568542568543, 0.8758915834522111, 0.8774928774928775]\n",
      "\n",
      "\n",
      "mean for accuracy in case of Naive Bayes is:  0.8694083694083694\n",
      "\n",
      "\n",
      "Standard Deviation for accuracy in case of Naive Bayes is:  0.01082154877878943\n",
      "\n",
      "\n",
      "mean for precision list in case of Naive Bayes is 0.8649684906823234\n",
      "\n",
      "\n",
      "Standard Deviation for precision list in case of Naive Bayes is 0.017104767454261264\n",
      "\n",
      "\n",
      "mean for recall score in case of Naive Bayes is 0.8889375412459919\n",
      "\n",
      "\n",
      "Standard Deviation for recall score in case of Naive Bayes is 0.016478153080216752\n",
      "\n",
      "\n",
      "mean for f1 score in case of Naive Bayes is 0.8765869348899032\n",
      "\n",
      "\n",
      "Standard Deviation for f1 score in case of Naive Bayes is 0.010196866726204193\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For Naive Bayes\n",
    "NB_model2 = GaussianNB()\n",
    "\n",
    "# Classification based on NB\n",
    "NB_accuracy_list = []\n",
    "NB_precision_list = []\n",
    "NB_recall_list = []\n",
    "NB_f1_list = []\n",
    "\n",
    "# Iteration for Retraining\n",
    "for i in random_seed_iterations:\n",
    "    # Random Dataset Split\n",
    "    x_train_dataA_NB, x_test_dataA_NB, y_train_dataA_NB, y_test_dataA_NB = train_test_split(z_standardized_dataA, np_label_dataA.ravel(), test_size = 0.3, random_state = i)\n",
    "\n",
    "    #Training the Model\n",
    "    NB_model2.fit(x_train_dataA_NB, y_train_dataA_NB)\n",
    "\n",
    "    #Test Dataset Prediction\n",
    "    y_predict_NB_list = NB_model2.predict(x_test_dataA_NB)\n",
    "\n",
    "    #Classification Accuracy\n",
    "    accuracy = metrics.accuracy_score(y_test_dataA_NB, y_predict_NB_list)\n",
    "    NB_accuracy_list.append(accuracy)\n",
    "    \n",
    "    #Precision\n",
    "    precision = metrics.precision_score(y_test_dataA_NB, y_predict_NB_list)\n",
    "    NB_precision_list.append(precision)\n",
    "                                    \n",
    "    #Recall\n",
    "    recall = metrics.recall_score(y_test_dataA_NB, y_predict_NB_list)\n",
    "    NB_recall_list.append(recall)\n",
    "    \n",
    "    #F1-score\n",
    "    f1score = metrics.f1_score(y_test_dataA_NB, y_predict_NB_list)\n",
    "    NB_f1_list.append(f1score)\n",
    "\n",
    "print(\"Acuracy list is :\",NB_accuracy_list)\n",
    "print(\"\\n\")\n",
    "print(\"Precision list is :\",NB_precision_list)\n",
    "print(\"\\n\")\n",
    "print(\"Recall list is:\",NB_recall_list)\n",
    "print(\"\\n\")\n",
    "print(\"F1-Score list is:\",NB_f1_list)\n",
    "print(\"\\n\")\n",
    "\n",
    "#Average and standard Deviation of Classification values\n",
    "mean_accuracy_list_NB = sum(NB_accuracy_list)/len(NB_accuracy_list)\n",
    "variance_accuracy_list_NB = sum([((x-mean_accuracy_list_NB)**2) for x in NB_accuracy_list])/len(NB_accuracy_list)\n",
    "sd_accuracy_list_NB = variance_accuracy_list_NB**0.5\n",
    "\n",
    "print(\"mean for accuracy in case of Naive Bayes is: \",mean_accuracy_list_NB)\n",
    "print(\"\\n\")\n",
    "print(\"Standard Deviation for accuracy in case of Naive Bayes is: \",sd_accuracy_list_NB)\n",
    "print(\"\\n\")\n",
    "mean_precision_list_NB=sum(NB_precision_list)/len(NB_precision_list)\n",
    "variance_precision_list_NB=sum([((x-mean_precision_list_NB)**2) for x in NB_precision_list])/len(NB_precision_list)\n",
    "sd_precision_list_NB=variance_precision_list_NB**0.5\n",
    "\n",
    "print(\"mean for precision list in case of Naive Bayes is\",mean_precision_list_NB)\n",
    "print(\"\\n\")\n",
    "print(\"Standard Deviation for precision list in case of Naive Bayes is\",sd_precision_list_NB)\n",
    "print(\"\\n\")\n",
    "\n",
    "mean_recall_score_list_NB=sum(NB_recall_list)/len(NB_recall_list)\n",
    "variance_recall_score_list_NB=sum([((x-mean_recall_score_list_NB)**2) for x in NB_recall_list])/len(NB_recall_list)\n",
    "sd_recall_score_list_NB=variance_recall_score_list_NB**0.5\n",
    "\n",
    "print(\"mean for recall score in case of Naive Bayes is\",mean_recall_score_list_NB)\n",
    "print(\"\\n\")\n",
    "print(\"Standard Deviation for recall score in case of Naive Bayes is\",sd_recall_score_list_NB)\n",
    "print(\"\\n\")\n",
    "\n",
    "mean_f1_score_list_NB=sum(NB_f1_list)/len(NB_f1_list)\n",
    "variance_f1_score_list_NB=sum([((x-mean_f1_score_list_NB)**2) for x in NB_f1_list])/len(NB_f1_list)\n",
    "sd_f1_score_list_NB=variance_f1_score_list_NB**0.5\n",
    "\n",
    "print(\"mean for f1 score in case of Naive Bayes is\",mean_f1_score_list_NB)\n",
    "print(\"\\n\")\n",
    "print(\"Standard Deviation for f1 score in case of Naive Bayes is\",sd_f1_score_list_NB)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree with 20 Iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracy list is : [0.9393939393939394, 0.9227272727272727, 0.9303030303030303, 0.9424242424242424, 0.9181818181818182, 0.9318181818181818, 0.9075757575757576, 0.9257575757575758, 0.9318181818181818, 0.9196969696969697, 0.9409090909090909, 0.9363636363636364, 0.9348484848484848, 0.943939393939394, 0.9378787878787879, 0.9272727272727272, 0.9303030303030303, 0.9242424242424242, 0.9242424242424242, 0.9090909090909091, 0.9318181818181818]\n",
      "\n",
      "\n",
      "Precision list is : [0.9452887537993921, 0.9246987951807228, 0.938953488372093, 0.9518072289156626, 0.9385964912280702, 0.9408284023668639, 0.9035087719298246, 0.9442815249266863, 0.9267605633802817, 0.906158357771261, 0.9568965517241379, 0.9529411764705882, 0.9378531073446328, 0.948170731707317, 0.9416666666666667, 0.9361702127659575, 0.9476744186046512, 0.9269005847953217, 0.9420731707317073, 0.9193083573487032, 0.9387755102040817]\n",
      "\n",
      "\n",
      "Recall is list : [0.933933933933934, 0.9219219219219219, 0.9281609195402298, 0.9349112426035503, 0.9067796610169492, 0.9271137026239067, 0.9169139465875371, 0.9147727272727273, 0.9454022988505747, 0.9363636363636364, 0.9327731092436975, 0.9257142857142857, 0.9405099150141643, 0.9395770392749244, 0.9442896935933147, 0.9194029850746268, 0.9209039548022598, 0.9269005847953217, 0.9088235294117647, 0.9088319088319088, 0.930635838150289]\n",
      "\n",
      "\n",
      "F1-Score is list : [0.9395770392749244, 0.9233082706766917, 0.9335260115606936, 0.9432835820895522, 0.9224137931034483, 0.933920704845815, 0.9101620029455081, 0.9292929292929293, 0.9359886201991465, 0.9210134128166915, 0.9446808510638298, 0.9391304347826087, 0.9391796322489392, 0.9438543247344461, 0.9429763560500696, 0.927710843373494, 0.9340974212034383, 0.9269005847953217, 0.9251497005988023, 0.9140401146131805, 0.9346879535558782]\n",
      "\n",
      "\n",
      "mean for accuracy in case of Decision Tree is:  0.9290764790764793\n",
      "\n",
      "\n",
      "Standard Deviation for accuracy in case of Decision Tree is:  0.009770409220022326\n",
      "\n",
      "\n",
      "mean for precision list in case of Decision Tree is 0.9366339460111723\n",
      "\n",
      "\n",
      "Standard Deviation for precision list in case of Decision Tree is 0.01387704347363387\n",
      "\n",
      "\n",
      "mean for recall score in case of Decision Tree is 0.9268874683153108\n",
      "\n",
      "\n",
      "Standard Deviation for recall score in case of Decision Tree is 0.011269749181363706\n",
      "\n",
      "\n",
      "mean for f1 score in case of Decision Tree is 0.9316616468488289\n",
      "\n",
      "\n",
      "Standard Deviation for f1 score in case of Decision Tree is 0.009577591281963452\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize Decision Tree\n",
    "DT_model2 = DecisionTreeClassifier()\n",
    "\n",
    "# Classification based on DT\n",
    "DT_accuracy_list = []\n",
    "DT_precision_list = []\n",
    "DT_recall_list = []\n",
    "DT_f1_list = []\n",
    "\n",
    "#Iteration for Retraining\n",
    "for i in random_seed_iterations:\n",
    "    #Random Dataset Split\n",
    "    x_train_dataA_DT, x_test_dataA_DT, y_train_dataA_DT, y_test_dataA_DT = train_test_split(z_standardized_dataA, np_label_dataA.ravel(),test_size = 0.3, random_state = i)\n",
    "\n",
    "    # Training the Model\n",
    "    DT_model2.fit(x_train_dataA_DT, y_train_dataA_DT)\n",
    "\n",
    "    # Test Dataset Prediction\n",
    "    y_predict_DT_list = DT_model2.predict(x_test_dataA_DT)\n",
    "\n",
    "    # Classification Accuracy\n",
    "    accuracy = metrics.accuracy_score(y_test_dataA_DT, y_predict_DT_list)\n",
    "    DT_accuracy_list.append(accuracy)\n",
    "    \n",
    "    #Precision\n",
    "    precision = metrics.precision_score(y_test_dataA_DT, y_predict_DT_list)\n",
    "    DT_precision_list.append(precision)\n",
    "                                    \n",
    "    #Recall\n",
    "    recall = metrics.recall_score(y_test_dataA_DT, y_predict_DT_list)\n",
    "    DT_recall_list.append(recall)\n",
    "    \n",
    "    #F1-score\n",
    "    f1score = metrics.f1_score(y_test_dataA_DT, y_predict_DT_list)\n",
    "    DT_f1_list.append(f1score)\n",
    "\n",
    "print(\"Acuracy list is :\",DT_accuracy_list)\n",
    "print(\"\\n\")\n",
    "print(\"Precision list is :\",DT_precision_list)\n",
    "print(\"\\n\")\n",
    "print(\"Recall is list :\",DT_recall_list)\n",
    "print(\"\\n\")\n",
    "print(\"F1-Score is list :\",DT_f1_list)\n",
    "print(\"\\n\")\n",
    "\n",
    "#Average and standard Deviation of Classification values\n",
    "mean_accuracy_list_DT=sum(DT_accuracy_list)/len(DT_accuracy_list)\n",
    "variance_accuracy_list_DT=sum([((x-mean_accuracy_list_DT)**2) for x in DT_accuracy_list])/len(DT_accuracy_list)\n",
    "sd_accuracy_list_DT=variance_accuracy_list_DT**0.5\n",
    "\n",
    "print(\"mean for accuracy in case of Decision Tree is: \",mean_accuracy_list_DT)\n",
    "print(\"\\n\")\n",
    "print(\"Standard Deviation for accuracy in case of Decision Tree is: \",sd_accuracy_list_DT)\n",
    "print(\"\\n\")\n",
    "mean_precision_list_DT=sum(DT_precision_list)/len(DT_precision_list)\n",
    "variance_precision_list_DT=sum([((x-mean_precision_list_DT)**2) for x in DT_precision_list])/len(DT_precision_list)\n",
    "sd_precision_list_DT=variance_precision_list_DT**0.5\n",
    "\n",
    "print(\"mean for precision list in case of Decision Tree is\",mean_precision_list_DT)\n",
    "print(\"\\n\")\n",
    "print(\"Standard Deviation for precision list in case of Decision Tree is\",sd_precision_list_DT)\n",
    "print(\"\\n\")\n",
    "\n",
    "mean_recall_score_list_DT=sum(DT_recall_list)/len(DT_recall_list)\n",
    "variance_recall_score_list_DT=sum([((x-mean_recall_score_list_DT)**2) for x in DT_recall_list])/len(DT_recall_list)\n",
    "sd_recall_score_list_DT=variance_recall_score_list_DT**0.5\n",
    "\n",
    "print(\"mean for recall score in case of Decision Tree is\",mean_recall_score_list_DT)\n",
    "print(\"\\n\")\n",
    "print(\"Standard Deviation for recall score in case of Decision Tree is\",sd_recall_score_list_DT)\n",
    "print(\"\\n\")\n",
    "\n",
    "mean_f1_score_list_DT=sum(DT_f1_list)/len(DT_f1_list)\n",
    "variance_f1_score_list_DT=sum([((x-mean_f1_score_list_DT)**2) for x in DT_f1_list])/len(DT_f1_list)\n",
    "sd_f1_score_list_DT=variance_f1_score_list_DT**0.5\n",
    "\n",
    "print(\"mean for f1 score in case of Decision Tree is\",mean_f1_score_list_DT)\n",
    "print(\"\\n\")\n",
    "print(\"Standard Deviation for f1 score in case of Decision Tree is\",sd_f1_score_list_DT)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1.5: Comment on obtained results\n",
    "\n",
    "#### In Question 1.2, the best k for k-NN from the given set is 15.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
